return ("green")
}
else {
return ("red")
}
}
# store coloring
open <- AMD$open
close <- AMD$close
candleColors <- mapply(candle_color, open, close)
head(candleColors)
```
```{r}
# transpose and reform into df
amd <- as.data.frame(t(AMD))
colnames(amd) <- as.character(unlist(amd[1,]))
amd <- amd[-1, ]
# drop volume row
amd <- amd[-c(5),]
# melt
amd <- melt(as.matrix(amd))
# rename columns
colnames(amd) <- c("type", "date", "value")
head(amd)
```
```{r}
## plotting data
# convert to numeric
amd$value <- as.numeric(as.character(amd$value))
# get price limits
minval <- round(min(amd$value))
maxval <- round(max(amd$value))
# set scales
dollars_scale <- 5
day_scale <- 7
# toggle x-ticks
ticks_on <- element_text(angle = -90, vjust = 0.3)
ticks_off <- element_blank()
ticks_status <- ticks_off
# plot
ggplot(amd) +
geom_boxplot(aes(x=date, y=value, group=date), coef=100, fill=candleColors) +
theme(axis.text.x = ticks_status) + coord_cartesian(ylim=c(minval, maxval)) + scale_y_continuous(breaks=seq(minval, maxval, dollars_scale)) +
labs(title="AMD", x="date", y="price")
```
```{r}
# SLR strategy
# 1) split data into train and test
# 2) fit SLR model using price and volume in train
# 3) buy, sell pts based on deviation over training timeframe
# 4) equity curve over training timeframe (Sharpe ratio, Drawdown)
# 5) buy, sell pts based on deviation over testing timeframe
# 6) equity curve over testing timeframe (Sharpe ratio, Drawdown)
# 7) compare performance
```
```{r}
## split data into train and test sets
# convert dates to numeric
amd_df <- as.data.frame(AMD)
enum <- 1:nrow(amd_df)
amd_df <- cbind(amd_df, enum)
# get split indexes
split_percent <- 0.7
split_indexes <- c(1:floor(split_percent * nrow(amd_df)))
# split train, test
train <- amd_df[split_indexes, ]
test <- amd_df[-split_indexes, ]
nrow(train)
nrow(test)
nrow(amd_df)
```
```{r}
## fit SLR on training
modfit_slr <- lm(data=train, adjusted ~ volume + enum)
summary(modfit_slr)
```
```{r}
## check assumptions, clearly not linear
plot(x=fitted(modfit_slr), y=rstudent(modfit_slr))
abline(0,0)
```
```{r}
## add fitted and rstd to train dataframe
# store fitted and rstd
fit_vals <- fitted(modfit_slr)
rstd_vals <- rstudent(modfit_slr)
# add to train
train <- cbind(train, fit_vals)
train <- cbind(train, rstd_vals)
head(train)
```
```{r}
## plot adjusted with fitted model
plot_model <- ggplot() +
geom_point(data=train, aes(x=enum, y=adjusted)) +
geom_line(data=train, aes(x=enum, y=fit_vals), linetype="longdash", color="blue", size=1) +
xlab("day") + ylab("price") + ggtitle("Fitted Model")
plot_model
```
```{r}
## algo based on deviation w/ equity curve
# buy: if (rstd <= -2)
# sell: if (rstd >= 2)
calc_signal <- function(rstd) {
divider = 1.4
signal = character(length(rstd))
for (i in 1:length(rstd)) {
if (rstd[i] >= divider) {
signal[i] = "SELL"
}
else if (rstd[i] <= -divider) {
signal[i] = "BUY"
}
else {
signal[i] = ""
}
}
return(signal)
}
```
```{r}
## clean signals
clean_duplicates <- function(signal) {
len = length(signal)
clean_signals = numeric(len)
clean_signals[1] = signal[1]
prev_signal = signal[1]
for (i in 1:(len-1)) {
curr_signal = signal[i+1]
if (curr_signal == prev_signal && prev_signal != "") {
clean_signals[i+1] = ""
}
else {
clean_signals[i+1] = curr_signal
}
prev_signal = curr_signal
}
return(clean_signals)
}
```
```{r}
train_signals <- calc_signal(train$rstd_vals)
train$train_signals <- clean_duplicates(train_signals)
head(train_signals)
```
```{r}
## plot fitted model with signals
ggplot() +
geom_point(data=train, aes(x=enum, y=adjusted)) +
geom_line(data=train, aes(x=enum, y=fit_vals), linetype="longdash", color="blue", size=1) +
xlab("day") + ylab("price") + ggtitle("Fitted Model") +
geom_text(data=train, aes(x=enum, y=adjusted, label=as.character(train_signals), color=ifelse(train_signals == "BUY", "green", "red")), nudge_x = 7) +
scale_color_manual(values = c("green", "red")) + theme(legend.position = "none")
```
```{r}
calc_equity <- function(price, signal, initial_equity) {
len <- length(signal)
sell <- numeric(1)
buy <- numeric(1)
equity <- numeric(len)
curr_equity = initial_equity
for (day in 1:len) {
curr_price = price[day]
curr_signal = signal[day]
if (curr_signal == "SELL") {
if (length(buy) == 0) {
sell <- append(sell, curr_price)
}
else {
# store initial buy position
# calc p&l
# remove buy position
# add change to curr_equity
# add curr_equity to equity array
}
}
}
}
```
knitr::opts_chunk$set(echo = TRUE)
## import libraries
library(tidyquant)
library(tidyverse)
library(ggplot2)
library(reshape2)
library(knitr)
library(gridExtra)
## retrieving data
# define timeframe
start_date = "2018-11-15"
end_date = "2019-11-25"
# get stock data
AMD <- tq_get("AMD", get="stock.prices", from=start_date, to=end_date)
# candlestick coloring function
candle_color <- function(open, close) {
if (open == close) {
return("gray")
}
else if (open < close) {
return ("green")
}
else {
return ("red")
}
}
# store coloring
open <- AMD$open
close <- AMD$close
candleColors <- mapply(candle_color, open, close)
head(candleColors)
# transpose and reform into df
amd <- as.data.frame(t(AMD))
colnames(amd) <- as.character(unlist(amd[1,]))
amd <- amd[-1, ]
# drop volume row
amd <- amd[-c(5),]
# melt
amd <- melt(as.matrix(amd))
# rename columns
colnames(amd) <- c("type", "date", "value")
head(amd)
## plotting data
# convert to numeric
amd$value <- as.numeric(as.character(amd$value))
# get price limits
minval <- round(min(amd$value))
maxval <- round(max(amd$value))
# set scales
dollars_scale <- 5
day_scale <- 7
# toggle x-ticks
ticks_on <- element_text(angle = -90, vjust = 0.3)
ticks_off <- element_blank()
ticks_status <- ticks_off
# plot
ggplot(amd) +
geom_boxplot(aes(x=date, y=value, group=date), coef=100, fill=candleColors) +
theme(axis.text.x = ticks_status) + coord_cartesian(ylim=c(minval, maxval)) + scale_y_continuous(breaks=seq(minval, maxval, dollars_scale)) +
labs(title="AMD", x="date", y="price")
## split data into train and test sets
# convert dates to numeric
amd_df <- as.data.frame(AMD)
enum <- 1:nrow(amd_df)
amd_df <- cbind(amd_df, enum)
# get split indexes
split_percent <- 0.7
split_indexes <- c(1:floor(split_percent * nrow(amd_df)))
# split train, test
train <- amd_df[split_indexes, ]
test <- amd_df[-split_indexes, ]
nrow(train)
nrow(test)
nrow(amd_df)
install.packages("caTools")
# load libraries
library(ggplot2)
library(caTools)
# import data
data <- read.csv("train_clean.csv")
# set seed for consistency
set.seed(123)
# define split
split = sample.split(data$SalePrice, SplitRatio = 2/3)
# split into train and test
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
# fit include all vars
modfit_mlr_all <- lm(formula = SalePrice ~ ., data = train)
# get only significant vars p <= 0.001 ***
sig_vars_mlr <- data.frame(summary(modfit_mlr_all)$coef[summary(modfit_mlr_all)$coef[,4] <= .001, 4])
# define sig vars in formula
sig_vars_mlr_formula <- paste(rownames(sig_vars_mlr), collapse = "+")
# define mlr w/ sig vars complete formula
mlr_formula <- paste("SalePrice ~", sig_vars_mlr_formula, sep = "")
# fit inclue sig vars
modfit_mlr_sig <- lm(formula = as.formula(mlr_formula), data = train)
# predict on test set
y_pred_test_mlr <- predict(modfit_mlr_sig, newdata = test)
# get percent error for predicted values
percent_actual_pred <- abs(test$SalePrice - y_pred_test_mlr) / test$SalePrice
# calc average error
avg_error <- mean(percent_actual_pred)
# details
summary(modfit_mlr_sig)
# avg error on test set
print(cat('the avg error is: ', avg_error))
summary(modfit_mlr_sig)$terms
summary(modfit_mlr_sig)$term.labels
summary(modfit_mlr_sig)$terms[4]
summary(modfit_mlr_sig)$intercept
# details
summary_mlr_sig <- summary(modfit_mlr_sig)
summary_mlr_sig$terms[8]
summary_mlr_sig$terms[[2]]
summary_mlr_sig$terms[[1]]
summary_mlr_sig$terms[[4]]
summary_mlr_sig$terms[[3]]
as.list(summary_mlr_sig$terms[[3]])
summary_mlr_sig$terms
summary_mlr_sig$terms["dataClasses"]
summary_mlr_sig$coefficients
names(summary_mlr_sig$coefficients)
attr(summary_mlr_sig$terms, "term.labels")
# store names of sig vars
names_mlr_sig <- attr(summary_mlr_sig$terms, "term.labels")
test[,names_mlr_sig]
install.packages("gtools")
test[, "MasVnrType" ]
test[, "MasVnrType"]
labels(test[, "MasVnrType"])
levels(test[, "MasVnrType"])
factor(test[, "MasVnrType"])
# load libraries
library(ggplot2)
library(gtools)
# import data
data <- read.csv("test.csv")
### --- data preprocessing --- ###
# --- function defs --- #
# replaces na in col w/ mean
replace_na_mean <- function(col) {
col_clean = ifelse(is.na(col),
ave(col, FUN = function(x) mean(x, na.rm = TRUE)),
col)
return(col_clean)
}
# encodes factor col w/ labels equal to level's index
encode_col <- function(col) {
lvls <- levels(factor(col))
labs <- seq(1, length(lvls))
col_encode <- as.numeric(factor(col, levels = lvls, labels = labs))
return(col_encode)
}
# --- taking care of missing numeric data --- #
# subset numeric data
data_numeric <- data[, sapply(data, is.numeric)]
# extract col names w/ na vals
numeric_names_has_na <- colnames(as.matrix(data_numeric))[colSums(is.na(as.matrix(data_numeric))) > 0]
# store cols w/ na vals
numeric_cols_has_na <- data_numeric[, numeric_names_has_na]
# clean cols w/ na
numeric_cols_clean <- as.data.frame(apply(as.matrix(numeric_cols_has_na), 2, replace_na_mean))
# check na
check_na_numeric <- colSums(is.na(as.matrix(numeric_cols_clean))) == 0
# check mean
mean_raw_numeric <- colMeans(as.matrix(numeric_cols_has_na), na.rm = TRUE)
mean_clean_numeric <- colMeans(as.matrix(numeric_cols_clean))
check_mean_numeric <- mean_raw_numeric == mean_clean_numeric
# replace dirty cols w/ clean cols
data_numeric_clean <- data_numeric
data_numeric_clean[, numeric_names_has_na] <- numeric_cols_clean
# final check na and mean
check_na_numeric_final <- colSums(is.na(as.matrix(data_numeric_clean))) == 0
mean_raw_numeric_final <- colMeans((as.matrix(data_numeric)), na.rm = TRUE)
mean_clean_numeric_final <- colMeans((as.matrix(data_numeric_clean)))
check_mean_numeric_final <- mean_raw_numeric_final == mean_clean_numeric_final
# --- scale the data --- #
# # separate id col from scaling
# id_numeric_clean <- as.data.frame(data_numeric_clean[,"Id"])
# colnames(id_numeric_clean) <- c("Id")
# id_col_index <- which(colnames(data_numeric_clean) == "Id")
# other_numeric_clean <- as.data.frame(data_numeric_clean[,-c(id_col_index)])
#
# # apply scale function
# other_scaled_clean <- as.data.frame(scale(other_numeric_clean))
#
# # combine id and scaled
# data_numeric_clean <- cbind(id_numeric_clean, other_scaled_clean)
# --- taking care of categorigcal data --- #
# subset factor data
# subset factor data
data_factor <- data[, sapply(data, is.factor)]
head(data_factor)
# convert na vals to factors
data_factor <- as.data.frame(na.replace(apply(data_factor, 2, as.factor), "NA"))
head(data_factor)
levels(factor(data_factor[,1]))
# convert na vals to factors
data_factor <- as.data.frame(na.replace(apply(data_factor, 2, as.factor), "NA"))
# encode cols
data_encoded <- apply(data_factor, 2, encode_col)
head(data_encoded)
levels(data_encoded[,1])
levels(factor(data_encoded[,1]))
apply(data_encoded, 2, levels)
apply(data_encoded, 2, level)
apply(data_encoded, 2, levels)
apply(data_encoded, 1, levels)
apply(data_factor, 2, levels)
sapply(data_encoded, levels)
data_factor
store_encoding <- function(col) {
lvls <- levels(factor(col))
labs <- seq(1, length(lvls))
key <- cbind(lvls, labs)
return(key)
}
apply(data_factor, 2, store_encoding)
store_encoding <- function(col) {
lvls <- levels(factor(col))
labs <- seq(1, length(lvls))
key <- as.data.frame(cbind(lvls, labs))
key.labs <- as.numeric(key.labs)
return(key)
}
apply(data_factor, 2, store_encoding)
store_encoding <- function(col) {
lvls <- levels(factor(col))
labs <- seq(1, length(lvls))
key <- as.data.frame(cbind(lvls, labs))
colnames(key) <- c("lvls", "labs")
key.labs <- as.numeric(key.labs)
return(key)
}
store_encoding <- function(col) {
lvls <- levels(factor(col))
labs <- seq(1, length(lvls))
key <- as.data.frame(cbind(lvls, labs))
colnames(key) <- c("lvls", "labs")
key.labs <- as.numeric(key.labs)
return(key)
}
apply(data_factor, 2, store_encoding)
store_encoding <- function(col) {
lvls <- levels(factor(col))
labs <- seq(1, length(lvls))
key <- as.data.frame(cbind(lvls, labs))
colnames(key) <- c("lvls", "labs")
key$labs <- as.numeric(key$labs)
return(key)
}
apply(data_factor, 2, store_encoding)
head(train)
train$SaleType
data_factor$SaleType
test$SaleType
# load libraries
library(ggplot2)
library(gtools)
# import data
data <- read.csv("train.csv")
### --- data preprocessing --- ###
# --- function defs --- #
# replaces na in col w/ mean
replace_na_mean <- function(col) {
col_clean = ifelse(is.na(col),
ave(col, FUN = function(x) mean(x, na.rm = TRUE)),
col)
return(col_clean)
}
# encodes factor col w/ labels equal to level's index
encode_col <- function(col) {
lvls <- levels(factor(col))
labs <- seq(1, length(lvls))
col_encode <- as.numeric(factor(col, levels = lvls, labels = labs))
return(col_encode)
}
# store encoding of factors
store_encoding <- function(col) {
lvls <- levels(factor(col))
labs <- seq(1, length(lvls))
key <- as.data.frame(cbind(lvls, labs))
colnames(key) <- c("lvls", "labs")
key$labs <- as.numeric(key$labs)
return(key)
}
# --- taking care of missing numeric data --- #
# subset numeric data
data_numeric <- data[, sapply(data, is.numeric)]
# extract col names w/ na vals
numeric_names_has_na <- colnames(as.matrix(data_numeric))[colSums(is.na(as.matrix(data_numeric))) > 0]
# store cols w/ na vals
numeric_cols_has_na <- data_numeric[, numeric_names_has_na]
# clean cols w/ na
numeric_cols_clean <- as.data.frame(apply(as.matrix(numeric_cols_has_na), 2, replace_na_mean))
# check na
check_na_numeric <- colSums(is.na(as.matrix(numeric_cols_clean))) == 0
# check mean
mean_raw_numeric <- colMeans(as.matrix(numeric_cols_has_na), na.rm = TRUE)
mean_clean_numeric <- colMeans(as.matrix(numeric_cols_clean))
check_mean_numeric <- mean_raw_numeric == mean_clean_numeric
# replace dirty cols w/ clean cols
data_numeric_clean <- data_numeric
data_numeric_clean[, numeric_names_has_na] <- numeric_cols_clean
# final check na and mean
check_na_numeric_final <- colSums(is.na(as.matrix(data_numeric_clean))) == 0
mean_raw_numeric_final <- colMeans((as.matrix(data_numeric)), na.rm = TRUE)
mean_clean_numeric_final <- colMeans((as.matrix(data_numeric_clean)))
check_mean_numeric_final <- mean_raw_numeric_final == mean_clean_numeric_final
# --- scale the data --- #
# # separate id col from scaling
# id_numeric_clean <- as.data.frame(data_numeric_clean[,"Id"])
# colnames(id_numeric_clean) <- c("Id")
# id_col_index <- which(colnames(data_numeric_clean) == "Id")
# other_numeric_clean <- as.data.frame(data_numeric_clean[,-c(id_col_index)])
#
# # apply scale function
# other_scaled_clean <- as.data.frame(scale(other_numeric_clean))
#
# # combine id and scaled
# data_numeric_clean <- cbind(id_numeric_clean, other_scaled_clean)
# --- taking care of categorigcal data --- #
# subset factor data
data_factor <- data[, sapply(data, is.factor)]
# convert na vals to factors
data_factor <- as.data.frame(na.replace(apply(data_factor, 2, as.factor), "NA"))
# encode cols
data_encoded <- apply(data_factor, 2, encode_col)
# --- combine cleaned numeric and factor data --- #
# bind cols
data_clean <- cbind(data_encoded, data_numeric_clean)
apply(data_factor, 2, store_encoding)
